{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_shorttext_Romanian_Predict.ipynb","version":"0.3.2","provenance":[{"file_id":"1xSSFcYyXzqcLQkWbInQTpo7kfQlJ6Oqh","timestamp":1565769409148},{"file_id":"1ks2gYdtOMlkTL-kdL3BiQnlYANfrj1I0","timestamp":1564477288088}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b3iWIxGnKLkc","colab_type":"text"},"source":["THIS code: https://github.com/bhaveshoswal/CNN-text-classification-keras\n","\n","Other links:\n","https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/\n","\n","\n","KAGGLE Text classif> https://www.kaggle.com/au1206/text-classification-using-cnn/comments"]},{"cell_type":"code","metadata":{"id":"-DcONUhWKshE","colab_type":"code","outputId":"5f0aa1b8-25fe-476d-f64d-53ddda2686e9","executionInfo":{"status":"ok","timestamp":1566208769079,"user_tz":-180,"elapsed":2930,"user":{"displayName":"RSS Admin","photoUrl":"https://lh6.googleusercontent.com/-tWE-0FO-bb4/AAAAAAAAAAI/AAAAAAAAAA8/woL2YgR5YeM/s64/photo.jpg","userId":"05275757757187577114"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8o4798x_IwTT","colab_type":"text"},"source":["# Load model"]},{"cell_type":"code","metadata":{"id":"0c2PYE1HIvU1","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model = load_model('/content/drive/My Drive/Colab Notebooks/TopicModelling/cnn_text_classif_5classes_new_punct.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPDGk6Q-JkRp","colab_type":"text"},"source":["# Read and process test data"]},{"cell_type":"code","metadata":{"id":"BXIc5LuiI4MD","colab_type":"code","colab":{}},"source":["import numpy as np\n","import re\n","\n","style=['publicistic', 'stiintific', 'beletristic', 'memorialistic', 'juridic']\n","\n","def clean_str(string):\n","    \"\"\"\n","    Tokenization/string cleaning for datasets.\n","    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n","    \"\"\"\n","    string = re.sub(r\"[^A-ZĂÎȘȚÂa-z0-9ăîșțâ(),!?\\'\\`]\", \" \", string)\n","    string = re.sub(r\"\\'s\", \" \\'s\", string)\n","    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n","    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n","    string = re.sub(r\"\\'re\", \" \\'re\", string)\n","    string = re.sub(r\"\\'d\", \" \\'d\", string)\n","    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n","    string = re.sub(r\",\", \" , \", string)\n","    string = re.sub(r\"!\", \" ! \", string)\n","    string = re.sub(r\"\\(\", \" \\( \", string)\n","    string = re.sub(r\"\\)\", \" \\) \", string)\n","    string = re.sub(r\"\\?\", \" \\? \", string)\n","    string = re.sub(r\"\\s{2,}\", \" \", string)\n","    return string.strip().lower()\n","  \n","  \n","def pad_sentences(sentences, padding_word=\"<PAD/>\"):\n","    \"\"\"\n","    Pads all sentences to the same length.\n","    Returns padded sentences.\n","    \"\"\"\n","    sequence_length = 365\n","    padded_sentences = []\n","    for i in range(len(sentences)):\n","        sentence = sentences[i]\n","        num_padding = sequence_length - len(sentence)\n","        new_sentence = sentence + [padding_word] * num_padding\n","        padded_sentences.append(new_sentence)\n","    return padded_sentences  \n","  \n","  \n","def read_vocab(vocab_file):\n","  vocabulary_inv = []\n","  with open(vocab_file) as f:\n","    for line in f.readlines():\n","      vocabulary_inv.append(line.strip())\n","\n","    # Mapping from word to index\n","    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n","    return [vocabulary, vocabulary_inv]\n","\n","  \n","  \n","def build_input_data(sentences,vocabulary):\n","    \"\"\"\n","    Maps sentences vectors based on a vocabulary.\n","    \"\"\"\n","    x = np.array([[vocabulary[word] if word in vocabulary else vocabulary['<UNK>'] for word in sentence] for sentence in sentences])\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZjm0YXfR8w3","colab_type":"text"},"source":["# EVALUATE"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Main9KsSKPa0","colab":{}},"source":["vocabulary, vocabulary_inv = read_vocab('/content/drive/My Drive/Colab Notebooks/TopicModelling/vocab_unk_punct.kv')\n","\n","def predict_style(input_text):\n","  sentences= [[wd for wd in clean_str(x).split()] for x in input_text]\n","  sentences_padded = pad_sentences(sentences)\n","  X_test = build_input_data(sentences_padded, vocabulary)\n","  #print (' '.join([vocabulary_inv[k] for k in X_test[0] if vocabulary_inv[k]!='<PAD/>']))\n","  print (\"Predicted style:\", style[int(np.argmax(model.predict(X_test)))].upper())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ou67pn3GQwtN","colab_type":"code","outputId":"f97e84ba-74ef-47cf-ab3c-be17c781b4e1","executionInfo":{"status":"ok","timestamp":1566208758097,"user_tz":-180,"elapsed":557,"user":{"displayName":"RSS Admin","photoUrl":"https://lh6.googleusercontent.com/-tWE-0FO-bb4/AAAAAAAAAAI/AAAAAAAAAA8/woL2YgR5YeM/s64/photo.jpg","userId":"05275757757187577114"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["input_text = 'acum, poemul poate fi narat, tocmai pentru că el a redobândit firescul prozei, al înseși existenței diurne'\n","predict_style([input_text])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Predicted style: PUBLICISTIC\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YK1XuleGmE8j","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}